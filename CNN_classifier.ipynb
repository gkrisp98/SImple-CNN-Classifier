{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN classifier",
      "provenance": [],
      "authorship_tag": "ABX9TyOYAUwiQ9F57W80YpIUPalS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gkrisp98/SImple-CNN-Classifier/blob/main/CNN_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ldI-lFy_l6n"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn0RdjNFA8uX"
      },
      "source": [
        "data_set = torchvision.datasets.FakeData(transform = transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XFWvrNVjjRf",
        "outputId": "c94906a9-973f-4eef-8e34-0ba84e496d36"
      },
      "source": [
        "len(data_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3AJy5YRlyML"
      },
      "source": [
        "train_size = int(0.7 * len(data_set))\n",
        "test_size = len(data_set) - train_size\n",
        "train_set, test_set = torch.utils.data.random_split(data_set, [train_size, test_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQPwpkvZCpC4",
        "outputId": "c39d8d13-9299-4aa1-b122-315cfda323cf"
      },
      "source": [
        "train_loader = DataLoader(train_set, batch_size=10, num_workers=1)\n",
        "num_of_pixels = len(train_set) * 224 * 224 *3\n",
        "\n",
        "total_sum = 0\n",
        "for batch in train_loader: total_sum += batch[0].sum()\n",
        "mean = total_sum / num_of_pixels\n",
        "\n",
        "sum_of_squared_error = 0\n",
        "for batch in train_loader: sum_of_squared_error += ((batch[0] - mean).pow(2)).sum()\n",
        "std = torch.sqrt(sum_of_squared_error / num_of_pixels)\n",
        "\n",
        "mean, std"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4993), tensor(0.2903))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ98kQdQrxBY",
        "outputId": "75542294-b6c6-4244-e385-0b6b4d3cd62c"
      },
      "source": [
        "test_loader = DataLoader(test_set, batch_size=10, num_workers=1)\n",
        "num_of_pixels = len(test_set) * 224 * 224 *3\n",
        "\n",
        "total_sum = 0\n",
        "for batch in test_loader: total_sum += batch[0].sum()\n",
        "mean = total_sum / num_of_pixels\n",
        "\n",
        "sum_of_squared_error = 0\n",
        "for batch in test_loader: sum_of_squared_error += ((batch[0] - mean).pow(2)).sum()\n",
        "std = torch.sqrt(sum_of_squared_error / num_of_pixels)\n",
        "\n",
        "mean, std"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4992), tensor(0.2903))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZn42wBgCBmk",
        "outputId": "8e04cc59-b293-4e19-9574-7476eaa765a0"
      },
      "source": [
        "train_loader = DataLoader(train_set, batch_size=100, shuffle = True)\n",
        "data = next(iter(train_loader))\n",
        "data[0].mean(), data[0].std()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4992), tensor(0.2903))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xRqkrZfr4MH",
        "outputId": "fe83d7a6-f30e-4314-9c71-f4bf8f84a417"
      },
      "source": [
        "test_loader = DataLoader(test_set, batch_size=32, shuffle = True, num_workers = 2)\n",
        "data = next(iter(test_loader))\n",
        "data[0].mean(), data[0].std()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4994), tensor(0.2902))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKsPAfneCRNu"
      },
      "source": [
        "train_set_normal = torchvision.datasets.FakeData(transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean,std)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAz_oVeSEF4l"
      },
      "source": [
        "def get_num_correct(preds,labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIjKGpkyETwh"
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "    self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n",
        "    \n",
        "    self.fc1 = nn.Linear(in_features=120*24*24, out_features=500)\n",
        "    self.out = nn.Linear(in_features=500, out_features=10)\n",
        "    #self.out = nn.Linear(in_features=100, out_features=10)\n",
        "  def forward(self, t):\n",
        "    #hidden conv layer 1\n",
        "    t = self.conv1(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    #hidden conv layer 2\n",
        "    t = self.conv2(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    #hidden conv layer 3\n",
        "    t = self.conv3(t)\n",
        "    t = F.relu(t)\n",
        "    t = F.max_pool2d(t, kernel_size=3, stride=2)\n",
        "\n",
        "    #hidden linear layer 1\n",
        "    t = t.reshape(-1,120*24*24)\n",
        "    t = self.fc1(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    #hidden linear layer 2\n",
        "    #t = self.fc2(t)\n",
        "    #t = F.relu(t)\n",
        "\n",
        "    #output layer\n",
        "    t = self.out(t)\n",
        "    t = F.softmax(t, dim=1)\n",
        "\n",
        "    return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSJdNRD-FsVu",
        "outputId": "de881df9-ed87-4f6c-ac8d-3140abfa87b9"
      },
      "source": [
        "#TRAINING\n",
        "network = Network()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 100)\n",
        "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(120): #70, for 74% acc\n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "  \n",
        "  for batch in train_loader:\n",
        "    images, labels = batch\n",
        "\n",
        "    preds = network(images) #pass batch\n",
        "    loss = F.cross_entropy(preds, labels) #calculate loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() #calculate gradients\n",
        "    optimizer.step() #update weights\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_correct += get_num_correct(preds, labels)\n",
        "\n",
        "  print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 total_correct: 74 loss: 16.22469735145569\n",
            "epoch: 1 total_correct: 86 loss: 16.10193419456482\n",
            "epoch: 2 total_correct: 86 loss: 16.085869073867798\n",
            "epoch: 3 total_correct: 79 loss: 16.0789053440094\n",
            "epoch: 4 total_correct: 86 loss: 16.071407794952393\n",
            "epoch: 5 total_correct: 86 loss: 16.070212364196777\n",
            "epoch: 6 total_correct: 95 loss: 16.065183877944946\n",
            "epoch: 7 total_correct: 86 loss: 16.061578273773193\n",
            "epoch: 8 total_correct: 86 loss: 16.058306455612183\n",
            "epoch: 9 total_correct: 86 loss: 16.052026748657227\n",
            "epoch: 10 total_correct: 95 loss: 16.046431064605713\n",
            "epoch: 11 total_correct: 103 loss: 16.03572726249695\n",
            "epoch: 12 total_correct: 107 loss: 16.02239418029785\n",
            "epoch: 13 total_correct: 118 loss: 16.003053665161133\n",
            "epoch: 14 total_correct: 111 loss: 15.973464012145996\n",
            "epoch: 15 total_correct: 138 loss: 15.92969012260437\n",
            "epoch: 16 total_correct: 127 loss: 15.923389911651611\n",
            "epoch: 17 total_correct: 174 loss: 15.796257495880127\n",
            "epoch: 18 total_correct: 111 loss: 15.912986278533936\n",
            "epoch: 19 total_correct: 160 loss: 15.72173547744751\n",
            "epoch: 20 total_correct: 194 loss: 15.566344499588013\n",
            "epoch: 21 total_correct: 231 loss: 15.454853773117065\n",
            "epoch: 22 total_correct: 250 loss: 15.245321989059448\n",
            "epoch: 23 total_correct: 270 loss: 15.094002723693848\n",
            "epoch: 24 total_correct: 306 loss: 14.817913293838501\n",
            "epoch: 25 total_correct: 315 loss: 14.555937051773071\n",
            "epoch: 26 total_correct: 305 loss: 14.436141729354858\n",
            "epoch: 27 total_correct: 316 loss: 14.24427342414856\n",
            "epoch: 28 total_correct: 316 loss: 14.162976861000061\n",
            "epoch: 29 total_correct: 316 loss: 14.099479913711548\n",
            "epoch: 30 total_correct: 316 loss: 14.110519528388977\n",
            "epoch: 31 total_correct: 316 loss: 14.06271767616272\n",
            "epoch: 32 total_correct: 316 loss: 14.020236492156982\n",
            "epoch: 33 total_correct: 316 loss: 14.012326002120972\n",
            "epoch: 34 total_correct: 316 loss: 13.976871967315674\n",
            "epoch: 35 total_correct: 316 loss: 13.96408236026764\n",
            "epoch: 36 total_correct: 316 loss: 13.979584217071533\n",
            "epoch: 37 total_correct: 316 loss: 13.968005895614624\n",
            "epoch: 38 total_correct: 316 loss: 13.92482328414917\n",
            "epoch: 39 total_correct: 351 loss: 13.7915700674057\n",
            "epoch: 40 total_correct: 374 loss: 13.681212544441223\n",
            "epoch: 41 total_correct: 376 loss: 13.633977890014648\n",
            "epoch: 42 total_correct: 373 loss: 13.613519430160522\n",
            "epoch: 43 total_correct: 384 loss: 13.479265689849854\n",
            "epoch: 44 total_correct: 384 loss: 13.474411606788635\n",
            "epoch: 45 total_correct: 384 loss: 13.499581813812256\n",
            "epoch: 46 total_correct: 384 loss: 13.508695602416992\n",
            "epoch: 47 total_correct: 384 loss: 13.435133457183838\n",
            "epoch: 48 total_correct: 402 loss: 13.295850157737732\n",
            "epoch: 49 total_correct: 431 loss: 13.149499297142029\n",
            "epoch: 50 total_correct: 427 loss: 13.162825465202332\n",
            "epoch: 51 total_correct: 448 loss: 13.039831399917603\n",
            "epoch: 52 total_correct: 447 loss: 12.922052502632141\n",
            "epoch: 53 total_correct: 440 loss: 12.981616616249084\n",
            "epoch: 54 total_correct: 461 loss: 12.842539310455322\n",
            "epoch: 55 total_correct: 448 loss: 12.828421354293823\n",
            "epoch: 56 total_correct: 451 loss: 12.71019983291626\n",
            "epoch: 57 total_correct: 451 loss: 12.631181478500366\n",
            "epoch: 58 total_correct: 482 loss: 12.531530976295471\n",
            "epoch: 59 total_correct: 487 loss: 12.448939323425293\n",
            "epoch: 60 total_correct: 516 loss: 12.310592889785767\n",
            "epoch: 61 total_correct: 518 loss: 12.243572473526001\n",
            "epoch: 62 total_correct: 507 loss: 12.252902269363403\n",
            "epoch: 63 total_correct: 501 loss: 12.283408164978027\n",
            "epoch: 64 total_correct: 512 loss: 12.194482564926147\n",
            "epoch: 65 total_correct: 518 loss: 12.113068342208862\n",
            "epoch: 66 total_correct: 518 loss: 12.045781016349792\n",
            "epoch: 67 total_correct: 518 loss: 12.012168884277344\n",
            "epoch: 68 total_correct: 518 loss: 12.00205147266388\n",
            "epoch: 69 total_correct: 518 loss: 11.992372989654541\n",
            "epoch: 70 total_correct: 518 loss: 11.989334225654602\n",
            "epoch: 71 total_correct: 518 loss: 11.98729658126831\n",
            "epoch: 72 total_correct: 518 loss: 11.983360767364502\n",
            "epoch: 73 total_correct: 518 loss: 11.981631636619568\n",
            "epoch: 74 total_correct: 518 loss: 11.977673053741455\n",
            "epoch: 75 total_correct: 518 loss: 11.975362181663513\n",
            "epoch: 76 total_correct: 518 loss: 11.973798513412476\n",
            "epoch: 77 total_correct: 518 loss: 11.972113966941833\n",
            "epoch: 78 total_correct: 518 loss: 11.97074544429779\n",
            "epoch: 79 total_correct: 518 loss: 11.96982753276825\n",
            "epoch: 80 total_correct: 518 loss: 11.96891450881958\n",
            "epoch: 81 total_correct: 518 loss: 11.968133091926575\n",
            "epoch: 82 total_correct: 518 loss: 11.96744167804718\n",
            "epoch: 83 total_correct: 518 loss: 11.966801047325134\n",
            "epoch: 84 total_correct: 518 loss: 11.966243982315063\n",
            "epoch: 85 total_correct: 518 loss: 11.9657062292099\n",
            "epoch: 86 total_correct: 518 loss: 11.965214133262634\n",
            "epoch: 87 total_correct: 518 loss: 11.964743852615356\n",
            "epoch: 88 total_correct: 518 loss: 11.964300155639648\n",
            "epoch: 89 total_correct: 518 loss: 11.963882684707642\n",
            "epoch: 90 total_correct: 518 loss: 11.96348249912262\n",
            "epoch: 91 total_correct: 518 loss: 11.963100790977478\n",
            "epoch: 92 total_correct: 518 loss: 11.96273946762085\n",
            "epoch: 93 total_correct: 518 loss: 11.962393879890442\n",
            "epoch: 94 total_correct: 518 loss: 11.962069511413574\n",
            "epoch: 95 total_correct: 518 loss: 11.961762070655823\n",
            "epoch: 96 total_correct: 518 loss: 11.961470246315002\n",
            "epoch: 97 total_correct: 518 loss: 11.961194276809692\n",
            "epoch: 98 total_correct: 518 loss: 11.960930943489075\n",
            "epoch: 99 total_correct: 518 loss: 11.96068012714386\n",
            "epoch: 100 total_correct: 518 loss: 11.960438847541809\n",
            "epoch: 101 total_correct: 518 loss: 11.96020495891571\n",
            "epoch: 102 total_correct: 518 loss: 11.959980010986328\n",
            "epoch: 103 total_correct: 518 loss: 11.959761023521423\n",
            "epoch: 104 total_correct: 518 loss: 11.959549307823181\n",
            "epoch: 105 total_correct: 518 loss: 11.959342002868652\n",
            "epoch: 106 total_correct: 518 loss: 11.959140419960022\n",
            "epoch: 107 total_correct: 518 loss: 11.958944201469421\n",
            "epoch: 108 total_correct: 518 loss: 11.95875358581543\n",
            "epoch: 109 total_correct: 518 loss: 11.958569288253784\n",
            "epoch: 110 total_correct: 518 loss: 11.958388924598694\n",
            "epoch: 111 total_correct: 518 loss: 11.958215594291687\n",
            "epoch: 112 total_correct: 518 loss: 11.958048105239868\n",
            "epoch: 113 total_correct: 518 loss: 11.957884430885315\n",
            "epoch: 114 total_correct: 518 loss: 11.957726240158081\n",
            "epoch: 115 total_correct: 518 loss: 11.957571387290955\n",
            "epoch: 116 total_correct: 518 loss: 11.957420110702515\n",
            "epoch: 117 total_correct: 518 loss: 11.957273483276367\n",
            "epoch: 118 total_correct: 518 loss: 11.957128763198853\n",
            "epoch: 119 total_correct: 518 loss: 11.956987738609314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLZp5aHnL1kF",
        "outputId": "63691a7b-5e9b-49b2-c111-69c3b76a5b49"
      },
      "source": [
        "total_correct / len(train_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.74"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPQEkiZL2lkH"
      },
      "source": [
        "Preds = network(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWqTEftL3w2Z"
      },
      "source": [
        "_, predicteD = torch.max(preds, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7WHgiSk323m",
        "outputId": "a14a826c-adc8-466b-ba49-a6582e441b8b"
      },
      "source": [
        "predicteD"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 5, 5, 4, 4, 3, 5, 5, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddmbDhP84MV2",
        "outputId": "f23a00fe-720e-47d7-9a6d-5d7369a035b7"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        preds = network(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(preds.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 8 %\n"
          ]
        }
      ]
    }
  ]
}